{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R786P/data-science-roadmap-2025_2026/blob/main/17_cloud_mlops/01_gradio_deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "!pip install pygit2==1.15.1\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/Fooocus.git\n",
        "%cd /content/Fooocus\n",
        "!python entry_with_update.py --share --always-high-vram"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 17_cloud_mlops/01_gradio_deployment.ipynb\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import gradio as gr\n",
        "\n",
        "# Load and prep data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\")\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df['TotalCharges'] = df['TotalCharges'].fillna(0)\n",
        "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Train model\n",
        "X = df[['tenure', 'MonthlyCharges', 'TotalCharges']]\n",
        "y = df['Churn']\n",
        "model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Prediction function\n",
        "def predict_churn(tenure, monthly_charges, total_charges):\n",
        "    # Handle empty input\n",
        "    if total_charges == 0 and tenure == 0:\n",
        "        total_charges = monthly_charges  # reasonable default\n",
        "\n",
        "    pred = model.predict([[tenure, monthly_charges, total_charges]])[0]\n",
        "    prob = model.predict_proba([[tenure, monthly_charges, total_charges]])[0][1]\n",
        "    result = \"‚úÖ Likely to Stay\" if pred == 0 else \"‚ö†Ô∏è Likely to Churn\"\n",
        "    confidence = f\"Confidence: {prob:.2f}\" if pred == 1 else f\"Confidence: {1-prob:.2f}\"\n",
        "    return result, confidence\n",
        "\n",
        "# Gradio UI\n",
        "demo = gr.Interface(\n",
        "    fn=predict_churn,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Tenure (months)\", value=12),\n",
        "        gr.Number(label=\"Monthly Charges ($)\", value=70),\n",
        "        gr.Number(label=\"Total Charges ($)\", value=840)\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Text(label=\"Prediction\"),\n",
        "        gr.Text(label=\"Confidence\")\n",
        "    ],\n",
        "    title=\"Customer Churn Predictor\",\n",
        "    description=\"Enter customer details to predict churn risk.\"\n",
        ")\n",
        "\n",
        "# Launch (will give public URL in Colab)\n",
        "print(\"üöÄ Launching Gradio app...\")\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "WPb8bBIHliv8",
        "outputId": "30990add-6fab-4ed2-ffa3-f33e462ce88e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Launching Gradio app...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://725e4842b698144c07.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://725e4842b698144c07.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}